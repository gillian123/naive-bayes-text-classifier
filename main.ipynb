{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten-fold Cross Validation Accuracy: 94.95%\n",
      "Finished writing to gng276.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, math, csv\n",
    "from sklearn.model_selection import KFold\n",
    "from csv import reader\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# import training data from trg.csv\n",
    "def import_train_data():\n",
    "    data = pd.read_csv(\"trg.csv\")\n",
    "    # get list of column names\n",
    "    headers = list(data.columns.values)\n",
    "    # separate into target and abstract values\n",
    "    target = data[headers[1]]\n",
    "    abstract = data[headers[2]]\n",
    "    return target, abstract\n",
    "\n",
    "# import data to be predicted from tst.csv\n",
    "def import_predict_data():\n",
    "    data = pd.read_csv(\"tst.csv\")\n",
    "    # get list of column names\n",
    "    headers = list(data.columns.values)\n",
    "    # get abstract values\n",
    "    abstract = data[headers[1]]\n",
    "    return abstract\n",
    "\n",
    "# train model using abstract and target values\n",
    "def train(abstract_train, target_train):\n",
    "    \n",
    "    # declare variables\n",
    "    aCount, bCount, eCount, vCount = 0,0,0,0\n",
    "    abstractCount = 0\n",
    "    wordDict = dict()\n",
    "    \n",
    "    # for each abstract\n",
    "    for i in range(abstract_train.size):\n",
    "        abstractCount += 1\n",
    "        \n",
    "        # count frequency of each target value A, B, E, V\n",
    "        target = target_train.iloc[i]\n",
    "        if (target == \"A\"):\n",
    "            aCount += 1\n",
    "        elif (target == \"B\"):\n",
    "            bCount += 1\n",
    "        elif (target == \"E\"):\n",
    "            eCount += 1\n",
    "        elif (target == \"V\"):\n",
    "            vCount += 1\n",
    "        \n",
    "        # get list of words in abstract\n",
    "        wordList = abstract_train.iloc[i].split()\n",
    "        \n",
    "        for word in wordList:\n",
    "            # convert word to lowercase\n",
    "            word = word.lower()\n",
    "            # eliminate word if it is a stop word or digit\n",
    "            if (word not in stopwordList and not word.isdigit()):\n",
    "                # lemmatize word to get root word\n",
    "                word = lemmatizer.lemmatize(word)\n",
    "                # add word to wordDict and add one to corresponding target value\n",
    "                if word not in wordDict:\n",
    "                    wordDict[word] = {\"A\": 0, \"B\": 0, \"E\": 0, \"V\": 0}\n",
    "                wordDict[word][target] += 1\n",
    "                        \n",
    "    # P(c) for each target value A, B, E, V\n",
    "    probA = aCount/float(abstractCount)\n",
    "    probB = bCount/float(abstractCount)\n",
    "    probE = eCount/float(abstractCount)\n",
    "    probV = vCount/float(abstractCount)\n",
    "\n",
    "    # count(c) for each target value A, B, E, V\n",
    "    numWordsA, numWordsB, numWordsE, numWordsV = 0,0,0,0\n",
    "    for word in wordDict:\n",
    "        for target in wordDict[word]:\n",
    "            if (target == \"A\"):\n",
    "                numWordsA += wordDict[word][target]\n",
    "            elif (target == \"B\"):\n",
    "                numWordsB += wordDict[word][target]\n",
    "            elif (target == \"E\"):\n",
    "                numWordsE += wordDict[word][target]\n",
    "            else:\n",
    "                numWordsV += wordDict[word][target]\n",
    "    \n",
    "    result_dict = {\"wordDict\": wordDict, \"probA\": probA, \"probB\": probB, \"probE\": probE, \"probV\": probV, \\\n",
    "                   \"numWordsA\": numWordsA, \"numWordsB\": numWordsB, \"numWordsE\": numWordsE, \"numWordsV\": numWordsV}\n",
    "    return result_dict\n",
    "\n",
    "# predict target values of abstracts\n",
    "def predict(abstract, train_results):\n",
    "    \n",
    "    # get variables from training results\n",
    "    wordDict = train_results.get(\"wordDict\")\n",
    "    probA = train_results.get(\"probA\")\n",
    "    probB = train_results.get(\"probB\")\n",
    "    probE = train_results.get(\"probE\")\n",
    "    probV = train_results.get(\"probV\")\n",
    "    probClasses = [probA, probB, probE, probV]\n",
    "    numWordsA = train_results.get(\"numWordsA\")\n",
    "    numWordsB = train_results.get(\"numWordsB\")\n",
    "    numWordsE = train_results.get(\"numWordsE\")\n",
    "    numWordsV = train_results.get(\"numWordsV\")\n",
    "    numWordsClasses = [numWordsA, numWordsB, numWordsE, numWordsV]\n",
    "\n",
    "    # |V| containing number of distinct words\n",
    "    numDistinctWords = len(train_results.get(\"wordDict\"))\n",
    "    \n",
    "    classes = [\"A\", \"B\", \"E\", \"V\"]\n",
    "    classPredictions = []\n",
    "    \n",
    "    # for each abstract\n",
    "    for i in range(abstract.size):\n",
    "        \n",
    "        # get list of words in abstract\n",
    "        wordList = abstract.iloc[i].split()\n",
    "        \n",
    "        classProb = []\n",
    "        \n",
    "        # calculate probability of abstract belonging to each class\n",
    "        for c in range(4):\n",
    "            prob = math.log(probClasses[c])\n",
    "            for word in wordList:\n",
    "                word = word.lower()\n",
    "                if (word not in stopwordList and not word.isdigit()):\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "                    if (word in wordDict):\n",
    "                        countWC = wordDict.get(word).get(classes[c])\n",
    "                        probWC = math.log((countWC + 1)/(numWordsClasses[c] + numDistinctWords))\n",
    "                        prob += probWC\n",
    "            classProb.append(prob)\n",
    "        \n",
    "        maxProb = max(classProb)\n",
    "        predictedClass = classes[classProb.index(maxProb)]\n",
    "        classPredictions.append(predictedClass)\n",
    "    \n",
    "    return classPredictions\n",
    "    \n",
    "# test predicted values with expected values of abstracts\n",
    "def test(abstract_test, target_test, train_results):\n",
    "    \n",
    "    # get class predictions for abstracts\n",
    "    classPredictions = predict(abstract_test, train_results)\n",
    "    \n",
    "    # calculate accuracy based on number of correct predictions between predicted and expected\n",
    "    correctPredictions = 0\n",
    "    for i in range(abstract_test.size):\n",
    "        if(classPredictions[i] == target_test.iloc[i]):\n",
    "            correctPredictions += 1\n",
    "            \n",
    "    accuracy = correctPredictions/abstract_test.size\n",
    "    return accuracy\n",
    "\n",
    "# apply ten fold cross validation to evaluate accuracy of model\n",
    "def ten_fold_cv(target, abstract):\n",
    "    \n",
    "    # set 10-fold cross validation\n",
    "    kf = KFold(n_splits=10)\n",
    "    # list of accuracies from 10-fold cross validation\n",
    "    accuracies = []\n",
    "\n",
    "    # for each fold\n",
    "    for train_index, test_index in kf.split(target, abstract):\n",
    "        \n",
    "        # get training and test sets\n",
    "        target_train, target_test = target.loc[train_index], target.loc[test_index]\n",
    "        abstract_train, abstract_test = abstract.loc[train_index], abstract.loc[test_index]\n",
    "        # train model\n",
    "        train_results = train(abstract_train, target_train)\n",
    "        # use training results to test model accuracy\n",
    "        test_accuracy = test(abstract_test, target_test, train_results)\n",
    "        accuracies.append(test_accuracy)\n",
    "\n",
    "    # calculate average accuracy of the 10 folds\n",
    "    avg_accuracy = sum(accuracies)/len(accuracies)*100\n",
    "    return avg_accuracy\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    # get training data\n",
    "    target_train, abstract_train = import_train_data()\n",
    "    # word lemmatizer and stop words list\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stopwordList = stopwords.words('english')\n",
    "    \n",
    "    # apply 10-fold cross validation to evaluate model accuracy\n",
    "    tenFoldAccuracy = ten_fold_cv(target_train, abstract_train)\n",
    "    print(\"Ten-fold Cross Validation Accuracy: \" + str(round(tenFoldAccuracy,2)) + \"%\")\n",
    "    \n",
    "    train_results = train(abstract_train, target_train)\n",
    "    abstract_predict = import_predict_data()\n",
    "    classPredictions = predict(abstract_predict, train_results)\n",
    "    \n",
    "    with open('gng276.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"id\", \"class\"])\n",
    "        for i in range(len(classPredictions)):\n",
    "            writer.writerow([i+1, classPredictions[i]])\n",
    "    print(\"Finished writing to gng276.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
